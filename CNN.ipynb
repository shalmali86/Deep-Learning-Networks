{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VXn8NbtgkP8U"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # Importing numpy for numerical operations\n",
        "import matplotlib.pyplot as plt  # Importing matplotlib for plotting images\n",
        "import cv2  # Importing OpenCV for image processing\n",
        "from tensorflow.keras.models import Sequential  # Importing Sequential API for building a model layer-by-layer\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D  # Importing layers for CNN model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading an image in grayscale mode\n",
        "image = cv2.imread('/content/dot.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Checking the shape of the original image\n",
        "image.shape\n",
        "\n",
        "# Resizing the image to 28x28 pixels\n",
        "image_resize = cv2.resize(image, (28, 28))\n",
        "\n",
        "# Reshaping the image to (1, 28, 28, 1) to be compatible with the Conv2D input\n",
        "image_input = image_resize.reshape(1, 28, 28, 1)\n",
        "\n",
        "# Defining a simple 3x3 filter for edge detection\n",
        "filter1 = np.array([[[[-1]], [[-1]], [[-1]]],\n",
        "                    [[[-1]], [[8]], [[-1]]],\n",
        "                    [[[-1]], [[-1]], [[-1]]]])"
      ],
      "metadata": {
        "id": "orCklIrgoAWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a Sequential model\n",
        "model = Sequential()\n",
        "# Adding a Conv2D layer with the custom filter and no activation (just applying convolution)\n",
        "model.add(Conv2D(1, kernel_size=(3, 3), input_shape=(28, 28, 1), activation=None, use_bias=False))\n",
        "# Setting the weights of the Conv2D layer to the custom filter defined above\n",
        "model.layers[0].set_weights([filter1])\n",
        "\n",
        "# Applying the convolutional filter to the input image\n",
        "conv_output = model.predict(image_input)\n",
        "\n",
        "# Removing single-dimensional entries from the output array (from (1, 26, 26, 1) to (26, 26))\n",
        "conv_output = np.squeeze(conv_output)\n",
        "\n",
        "# Plotting the original resized image and the filtered image\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax[0].imshow(image_resize, cmap='gray')  # Showing the resized input image\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(conv_output, cmap='gray')  # Showing the convolutional output image\n",
        "ax[1].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HwiHfl07oHK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading necessary libraries again for the second part\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Importing functions to load and convert images"
      ],
      "metadata": {
        "id": "DIphrz9voOcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a grayscale image, resizing it to 128x128 pixels\n",
        "img = load_img('/content/African_Bush_Elephant.jpg', target_size=(128, 128), color_mode='grayscale')\n",
        "# Converting the image to a NumPy array for model compatibility\n",
        "img_array = img_to_array(img)\n",
        "# Expanding dimensions to make it suitable for model input (from (128,128,1) to (1,128,128,1))\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Displaying the image array shape\n",
        "img_array"
      ],
      "metadata": {
        "id": "B16-ApZToS3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the image array values to a range of 0-1 by dividing by 255\n",
        "image_array = img_array / 255.0\n"
      ],
      "metadata": {
        "id": "nTsA0jeioXR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a Sequential model with a single Conv2D layer\n",
        "model = Sequential()\n",
        "# Adding a Conv2D layer with 32 filters, 3x3 kernel, ReLU activation, and same padding\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1), padding='same'))\n",
        "# Compiling the model with Adam optimizer and categorical crossentropy loss\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n"
      ],
      "metadata": {
        "id": "hdCSnbz1osPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the feature maps by passing the image through the Conv2D layer\n",
        "conv_output = model.predict(image_array)\n",
        "# Squeezing the output to remove unnecessary dimensions\n",
        "features_maps = np.squeeze(conv_output)\n",
        "\n",
        "# Plotting each of the 32 feature maps\n",
        "fig, axarr = plt.subplots(4, 8, figsize=(15, 10))  # Creating a grid of subplots\n",
        "for i in range(32):  # Looping through each feature map\n",
        "  ax = axarr[i // 8, i % 8]  # Selecting subplot based on index\n",
        "  ax.imshow(features_maps[:, :, i], cmap='gray')  # Displaying each feature map in grayscale\n",
        "  ax.axis('off')  # Hiding axes for cleaner visualization\n",
        "plt.show()  # Displaying the feature maps"
      ],
      "metadata": {
        "id": "-Ns0iFGMouiH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}